{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./ex3_train.csv')\n",
    "test_data = pd.read_csv('./ex3_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (3500, 400)\n",
      "y_train:  (3500,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.iloc[:, train_data.columns != 'y']\n",
    "y_train = train_data[\"y\"]\n",
    "X_test = test_data.iloc[:, test_data.columns != 'y']\n",
    "y_test = test_data[\"y\"]\n",
    "\n",
    "X_train_array = np.asarray(X_train)\n",
    "y_train_array = np.asarray(y_train)\n",
    "X_test_array = np.asarray(X_test)\n",
    "y_test_array = np.asarray(y_test)\n",
    "\n",
    "print (\"X_train: \", X_train_array.shape)\n",
    "print (\"y_train: \", y_train_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(y, numOfClasses):\n",
    "    encoded = np.zeros((y.shape[0],numOfClasses))\n",
    "    for i in range(y.shape[0]):\n",
    "        encoded[i,y[i]] = 1.0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 10)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded = one_hot_encoding(y_train_array, 10)\n",
    "y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "output_layer_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(input_layer_size,hidden_layer_size,output_layer_size):\n",
    "    np.random.seed(1)\n",
    "    w1 = np.random.rand(hidden_layer_size, input_layer_size) * 0.01\n",
    "    w2 = np.random.rand(output_layer_size, hidden_layer_size) * 0.01\n",
    "    return (w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 400)\n",
      "(10, 25)\n"
     ]
    }
   ],
   "source": [
    "w1, w2 = initialize_weights(input_layer_size, hidden_layer_size, output_layer_size)\n",
    "print (w1.shape)\n",
    "print (w2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing bias weights to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1:  (25, 1)\n",
      "b2:  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "bias1 = np.zeros((hidden_layer_size, 1))\n",
    "print (\"b1: \", bias1.shape)\n",
    "bias2 = np.zeros((output_layer_size, 1))\n",
    "print (\"b2: \", bias2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, w1, w2, b1, b2):\n",
    "    a0 = X\n",
    "    z1 = (np.dot(a0,w1.T).T + b1)\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = (np.dot(w2, a1)+ b2)\n",
    "    a2 = sigmoid(z2).T\n",
    "    return a0,a1,a2,z1,z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0, a1, a2, z1, z2 = forward_propagation(X_train_array, w1, w2, bias1, bias2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(prediction, actual):\n",
    "    print (actual.shape[0])\n",
    "    loss = np.multiply(actual, np.log(prediction)) + np.multiply((1-actual), np.log(1 - prediction))\n",
    "    cost = (-1/actual.shape[0]) * np.sum(loss)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.2301203322052228"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(a2, y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagation(a1,a2,X,y,w1,w2,b1,b2):\n",
    "    m = y.shape[0]\n",
    "    dz2 = a2-y\n",
    "#     print(dz2.shape)\n",
    "    dw2 = (1/m) * np.dot(dz2.T, a1.T)\n",
    "#     print (dw2.shape)\n",
    "    db2 = (1/m) * np.sum(dz2.T, axis=1, keepdims=True)\n",
    "#     print (db2.shape)\n",
    "    da1 = np.dot(dz2, w2)\n",
    "    dz1 = (1/m) * np.multiply(da1.T,np.multiply(a1,(1-a1)))\n",
    "#     print (dz1.shape)\n",
    "    dw1 = (1/m) * np.dot(dz1, X)\n",
    "#     print (dw1.shape)\n",
    "    db1 = (1/m) * np.sum(dz1, axis=1, keepdims=True)\n",
    "    return dw1, dw2, db1, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw1, dw2, db1, db2 = backward_propagation(a1, a2, X_train_array, y_train_encoded, w1, w2, bias1, bias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w1, w2, b1, b2, alpha,ep):\n",
    "    m = y.shape[1]\n",
    "    cost_history = []\n",
    "    epochs = 0\n",
    "#     a0, a1, a2, z1, z2 = forward_propagation(X, w1, w2, b1, b2)\n",
    "#     newCost = compute_cost(a2, y)\n",
    "#     oldCost = float('inf')\n",
    "#     cost_history.append(newCost)\n",
    "    while epochs < ep:\n",
    "#     while newCost < oldCost and abs(newCost - oldCost) > 1e-5 or epochs < ep:\n",
    "        a0, a1, a2, z1, z2 = forward_propagation(X, w1, w2, b1, b2)\n",
    "        newCost = compute_cost(a2, y)\n",
    "        cost_history.append(newCost)\n",
    "        dw1, dw2, db1, db2 = backward_propagation(a1, a2, X, y, w1, w2, b1, b2)\n",
    "    \n",
    "        # update weights\n",
    "        w1 = w1 - (alpha * dw1)\n",
    "        w2 = w2 - (alpha * dw2)\n",
    "        b1 = b1 - (alpha * db1)\n",
    "        b2 = b2 - (alpha * db2)\n",
    "        epochs = epochs + 1\n",
    "        \n",
    "    min_cost_iter = cost_history.index(min(cost_history))\n",
    "    print (\"Minimum cost at iteration: \", min_cost_iter)\n",
    "    print (\"Minimum cost achieved: \", min(cost_history))\n",
    "    print(cost_history[-1])\n",
    "    return cost_history, w1, w2, b1, b2     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    mat = np.exp(x)\n",
    "    return mat / mat.sum(0)\n",
    "\n",
    "def predict(w1, w2, b1, b2, X):\n",
    "    m = X.shape[0]\n",
    "    num_labels = w2.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    h1 = sigmoid((np.dot(X,w1.T).T + b1).T)\n",
    "    h2 = sigmoid((np.dot(h1,w2.T).T + b2).T)\n",
    "    p = softmax(h2)\n",
    "#     print (p)\n",
    "    actual_pred = []\n",
    "    for item in p:\n",
    "        actual_pred.append(np.argmax(item))\n",
    "    return actual_pred\n",
    "\n",
    "def accuracy(actual, predicted):\n",
    "    count = 0\n",
    "    for x,y in zip(actual, predicted):\n",
    "        if x == y:\n",
    "            count = count + 1\n",
    "    return count/actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum cost at iteration:  29999\n",
      "Minimum cost achieved:  0.594816505733\n",
      "0.594816505733\n"
     ]
    }
   ],
   "source": [
    "cost_history01, wl_result01, w2_result01, b1_res01, b2_res01 = gradient_descent(X_train_array,y_train_encoded,w1,w2,\\\n",
    "                                                                                bias1, bias2, 1, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "predictions01 = predict(wl_result01, w2_result01, b1_res01, b2_res01, X_test_array)\n",
    "accuracy01 = accuracy(y_test_array, predictions01)\n",
    "print (accuracy01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history001, wl_result001, w2_result001, b1_res001, b2_res001 = gradient_descent(X_train_array, y_train_encoded, w1, w2, bias1,\\\n",
    "                                                                      bias2, 0.001, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history1, wl_result1, w2_result1, b1_res1, b2_res1 = gradient_descent(X_train_array,y_train_encoded,w1,w2,\\\n",
    "                                                                                bias1,bias2,0.1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
